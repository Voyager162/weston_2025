{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "layout: page\n",
    "title: 5.1 homework and popcorn hacks\n",
    "permalink: /posts/5.1/\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Popcorn Hack #1\n",
    "Technology can improve efficiency and time management to be have autonomous systems be doing things that humans used to do, allowing humans to run more important tasks. But with this it can cause issues that when the program runs into an issue it is not made to handle, it can cause a lot of problems.\n",
    "\n",
    "One example is the self-driving car. It is a great idea to have a car that can drive itself, but if it runs into a situation that it is not programmed to handle, it can cause a lot of issues. For example, if a self-driving car is driving down the road and a deer jumps out in front of it, the car may not know how to react and could cause an accident.\n",
    "\n",
    "## Popcorn Hack #2\n",
    "Negative effects in technology mean that it can cause issues in the workplace. For example, if a company relies too heavily on technology to do tasks that humans used to do, it can lead to job loss. If a company automates a process that used to be done by humans, it can lead to people losing their jobs. This can cause a lot of issues in the economy and can lead to people struggling to find work.\n",
    "\n",
    "In order to code responsibly to avoid these issues, it is important to find a balance between using technology to improve efficiency and ensuring that humans are still involved in the process. This can be done by using technology to assist humans in their tasks, rather than replacing them entirely. For example, using technology to help with data analysis, but still having humans make the final decisions.\n",
    "\n",
    "## Popcorn Hack #3\n",
    "It's important to understand the unintended consequences of tecnology, especially dopamine driven technology. For example, social media platforms are designed to keep users engaged and coming back for more. This can lead to addiction and negative effects on mental health. It's important to be aware of these consequences and to use technology in moderation.\n",
    "\n",
    "## Homework Hack #1\n",
    "AI Innovation: Facial Recognition.\n",
    "\n",
    "Original Use: Designed for identifying individuals by analyzing facial features, primarily for security purposes (e.g., unlocking phones, surveillance, border control).\n",
    "\n",
    "New Use Case:\n",
    "Using facial recognition to monitor students’ engagement levels in online learning. The AI could analyze facial expressions, eye movements, and attentiveness to detect if students are focused, distracted, or fatigued. It could provide real-time feedback to teachers or adaptive learning platforms, helping them adjust content or delivery methods accordingly.\n",
    "\n",
    "Impact:\n",
    "\n",
    "- ✅ Benefits:\n",
    "\n",
    "    - Improved learning outcomes: Teachers can quickly identify disengaged students and intervene, providing more personalized support.\n",
    "    - Enhanced online education: Adaptive platforms can modify content in real time, making lessons more dynamic and effective.\n",
    "- ⚠️ Risks:\n",
    "\n",
    "    - Privacy concerns: Continuous facial monitoring may raise ethical issues regarding student privacy and data security.\n",
    "    - Potential biases: The AI may misinterpret facial expressions, leading to inaccurate assessments of engagement, especially for students with diverse facial features or neurodivergent traits.\n",
    "\n",
    "## Homework Hack #2\n",
    "Problem: Misinformation spread by AI-generated content.\n",
    "\n",
    "Risk:\n",
    "AI-powered tools, such as language models and deepfake generators, can create convincing fake news, images, or videos. This can spread false information quickly, influencing public opinion, damaging reputations, and eroding trust in reliable sources.\n",
    "\n",
    "Solution 1:\n",
    "- ✅ Content verification algorithms: Develop AI models that specialize in detecting and flagging synthetic or manipulated content. These models could verify the authenticity of text, images, and videos by comparing them to verified databases or using watermarking techniques.\n",
    "\n",
    "Solution 2:\n",
    "- ✅ AI transparency policies: Implement regulations requiring AI-generated content to include clear labels or disclaimers (e.g., “AI-generated” or “synthetic content”). This would help users distinguish between real and fake information.\n",
    "\n",
    "Reflection:\n",
    "Ethical AI development is essential to prevent harm and build trust in technology. Without proper safeguards, AI can be misused to deceive and manipulate. By promoting transparency, accountability, and fairness, we can harness AI’s potential responsibly and protect society from unintended consequences.\n",
    "\n",
    "## Homework Hack #3\n",
    "AI Example: Amazon’s AI Hiring Tool.\n",
    "\n",
    "What Happened: Amazon developed an AI recruitment tool to automate the hiring process and select top candidates. However, the AI unintentionally discriminated against women. The model was trained on past hiring data, which primarily favored male candidates. As a result, the AI penalized resumes containing terms like “women’s” (e.g., “women’s chess club”) and downgraded applications from female candidates.\n",
    "\n",
    "Response: Amazon discontinued the tool after discovering the bias. The company stated that it did not rely entirely on the AI for hiring decisions, but it ultimately scrapped the project due to its flawed performance.\n",
    "\n",
    "Prevention:\n",
    "- ✅ Diverse training data: Developers could have used a more representative dataset with balanced gender, race, and experience samples. This would help the model learn unbiased patterns.\n",
    "- ✅ Bias audits and fairness testing: Regularly auditing the AI for discriminatory patterns through fairness testing could have detected the gender bias earlier, preventing its deployment."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
